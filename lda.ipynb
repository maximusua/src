{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.030*\"call\" + 0.010*\"2\" + 0.009*\"free\" + 0.009*\"txt\"'), (1, '0.010*\"good\" + 0.010*\"day\" + 0.008*\"love\" + 0.008*\"free\"'), (2, '0.034*\"u\" + 0.015*\"im\" + 0.009*\"2\" + 0.009*\"ok\"')]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import Word2Vec as w2v\n",
    "import codecs\n",
    "\n",
    "labels = []\n",
    "textsPOS = []\n",
    "textsNEG = []\n",
    "texts = []\n",
    "with codecs.open(\"spam.csv\", \"r\", \"ISO-8859-1\") as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        try:\n",
    "                if row[0] == 'ham':\n",
    "                        labels.append(0)\n",
    "                        textsNEG.append(row[1])\n",
    "                elif row[0] == 'spam':\n",
    "                        labels.append(1)\n",
    "                        textsPOS.append(row[1])\n",
    "                texts.append(row[1])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in texts]   \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "model = w2v(doc_clean, size=30, window=5, min_count=5)\n",
    "W = model.wv.vocab.items()\n",
    "\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)\n",
    "\n",
    "print(ldamodel.print_topics(num_topics=10, num_words=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
