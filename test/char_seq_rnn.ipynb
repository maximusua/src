{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1559e306ba8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mchar_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharModelRnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linux_input_test.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mchar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class CharModelRnn:\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self._vocabs = dict()\n",
    "        self._text = []\n",
    "    \n",
    "       \n",
    "        with codecs.open(file_path, \"r\", \"ISO-8859-1\") as f:\n",
    "            text = f.read()\n",
    "            for ch in text:\n",
    "                if ch not in self._vocabs:\n",
    "                    self._vocabs[ch] = 0\n",
    "                self._vocabs[ch] += 1\n",
    "                self._text.append(ch)\n",
    "        self._char_indices = dict((c, i) for i, c in enumerate(self._vocabs.keys()))\n",
    "        self._indices_char = dict((i, c) for i, c in enumerate(self._vocabs.keys()))\n",
    "        \n",
    "        self._sentences = []\n",
    "        self._next_chars = []\n",
    "        for i in range(0, len(self._text)-1):\n",
    "            self._sentences.append(text[i])\n",
    "            self._next_chars.append(text[i + 1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        self._model = Sequential()\n",
    "        self._model.add(LSTM(128, input_shape=(1, len(self._vocabs))))\n",
    "        self._model.add(Dense(1, activation='sigmoid'))\n",
    "        self._model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    def train():\n",
    "        X = np.zeros((len(sentences), 1, len(chars)), dtype=np.bool)\n",
    "        y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "        for i, char in enumerate(sentences):           \n",
    "            X[i, char_indices[sentences[i]]] = 1\n",
    "            y[i, char_indices[next_chars[i]]] = 1\n",
    "        \n",
    "        self._model.fit(X, y, batch_size=128, epochs=1000, verbose=2)\n",
    "        \n",
    "    def next_letter(self, chars):\n",
    "        stats = self.stats(chars);\n",
    "        c_keys = list(stats.keys())\n",
    "        c_p = list(stats.values())\n",
    "        c_next = np.random.choice(c_keys, 1, p=c_p)[0];\n",
    "        return c_next\n",
    "\n",
    "    def gen_text(self, text_len):\n",
    "        last_chars = ['\\\\'] * self._nlen\n",
    "        res = []\n",
    "        for i in range(text_len):\n",
    "            ch = self.next_letter(''.join(last_chars))\n",
    "            del last_chars[0:1]\n",
    "            last_chars.append(ch);\n",
    "            \n",
    "            res.append(ch)\n",
    "        return \"\".join(res)\n",
    "\n",
    "\n",
    "char_model = CharModelRnn('linux_input_test.txt')\n",
    "print('read')\n",
    "char_model.train()\n",
    "print('after train')\n",
    "\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "\n",
    "deep_len = 30\n",
    "need_len = 10000\n",
    "#char_model = CharModel('linux_input.txt', deep_len, False)\n",
    "\n",
    "#for _ in range(10):\n",
    "    #print(char_model.next_letter('pri'))\\\n",
    "\n",
    "#text = char_model.gen_text(need_len)\n",
    "#print(text)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
